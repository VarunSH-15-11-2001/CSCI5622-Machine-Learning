{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "# import time as t\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Breast_Cancer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(point1, point2):\n",
    "    \"\"\"\n",
    "        Age, survival months, regional node positive, regional node examined and Tumor size\n",
    "        are the continuous variables. Euclidean distance is used for measuring similarity \n",
    "        between these variables.\n",
    "\n",
    "        Race, Marital Status, T Stage, N Stage, 6th Stage, Defferentiated, Grade, A Stage, \n",
    "        Estrogen Status, Progesterone Status are the categorical values. Hamming distance \n",
    "        is used for measuring the similarity across these variables.\n",
    "    \"\"\"\n",
    "    euclidean_distance = math.sqrt(\n",
    "        (point1['Age'] - point2['Age'] ) **2+\n",
    "        (point1['Tumor Size'] - point2['Tumor Size'] ) **2+\n",
    "        (point1['Regional Node Examined'] - point2['Regional Node Examined']) **2+\n",
    "        (point1['Regional Node Positive'] - point2['Regional Node Positive'] ) **2+\n",
    "        (point1['Survival Months'] - point2['Survival Months'])**2\n",
    "    )\n",
    "\n",
    "    # print(\"ed: \", euclidean_distance)\n",
    "\n",
    "    \n",
    "\n",
    "    hamming_distance = (\n",
    "        (0 if point1['Race']==point2['Race'] else 1) + \n",
    "        (0 if point1['Marital Status']==point2['Marital Status'] else 1) +\n",
    "        (0 if point1['T Stage']==point2['T Stage'] else 1) +\n",
    "        (0 if point1['N Stage']==point2['N Stage'] else 1) +\n",
    "        (0 if point1['6th Stage']==point2['6th Stage'] else 1) +\n",
    "        (0 if point1['differentiate']==point2['differentiate'] else 1) +\n",
    "        (0 if point1['Grade']==point2['Grade'] else 1) +\n",
    "        (0 if point1['A Stage']==point2['A Stage'] else 1) +\n",
    "        (0 if point1['Estrogen Status']==point2['Estrogen Status'] else 1) +\n",
    "        (0 if point1['Progesterone Status']==point2['Progesterone Status'] else 1) \n",
    "    )\n",
    "    \n",
    "    \n",
    "    # print(\"hd: \", hamming_distance)\n",
    "    return euclidean_distance + hamming_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into train, val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    totalRows = data.shape[0] - 1\n",
    "\n",
    "    \"\"\"\n",
    "        split data into train, validation and testing sets : 75-15-15% each\n",
    "        find the total size of the dataset and *0.75, .15, .15\n",
    "    \"\"\"\n",
    "\n",
    "    train_boundary = math.floor(0.70*totalRows)\n",
    "    val_boundary = train_boundary + math.ceil(0.15*totalRows)\n",
    "    test_boundary = val_boundary + math.ceil(0.15*totalRows)\n",
    "\n",
    "    train_data = data.iloc[:train_boundary]\n",
    "    val_data = data.iloc[train_boundary:val_boundary]\n",
    "    test_data = data.iloc[val_boundary:test_boundary]\n",
    "\n",
    "    train_Y = train_data['Status']\n",
    "    train_X = train_data.drop(['Status'], axis=1)\n",
    "\n",
    "    val_Y = val_data['Status']\n",
    "    val_X = val_data.drop(['Status'], axis=1)\n",
    "\n",
    "\n",
    "    test_Y = test_data['Status']\n",
    "    test_X = test_data.drop(['Status'], axis=1)\n",
    "\n",
    "    # print(train_X.shape[0])\n",
    "    # print(val_X.shape[0])\n",
    "\n",
    "    return train_X, train_Y, val_X, val_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, val_X, val_Y, test_X, test_Y = split_dataset(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given a value of K, what are the predictions \n",
    "# for the 'Status' label on the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tuning_knn(data, k):\n",
    "    \n",
    "    train_X, train_Y, val_X, val_Y, test_X, test_Y = split_dataset(data=data)\n",
    "\n",
    "    val_pred = {}\n",
    "    point_distance_map = {}\n",
    "\n",
    "    point_point_map = {}\n",
    "\n",
    "    for val_index in tqdm(range(list(val_X.shape)[0])):\n",
    "\n",
    "        \"\"\"\n",
    "            for every point in the validation dataset, find the k nearest neighbours by computing distances,\n",
    "            map and store distances to its training point, sort the map, and look at the first k points.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # print(\"Iterating at val_point: \", val_index)\n",
    "\n",
    "        for train_index in range(list(train_X.shape)[0]):\n",
    "            # print(\"Iterating at train_point: \", train_index)\n",
    "            distance_list=[]\n",
    "            point_list=[]\n",
    "            # print(val_index, train_index)\n",
    "            distance = compute_distances(val_X.iloc[val_index], train_X.iloc[train_index])\n",
    "            point_distance_map[train_index] = distance\n",
    "\n",
    "    \n",
    "        sorted_distances_point_map = dict(sorted(point_distance_map.items(), key=lambda item: item[1]))\n",
    "        \n",
    "        \"\"\"\n",
    "            while looking at the first k points, find the most occuring 'Status' value among them, using\n",
    "            train_Y and report it as the output for that val_point\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        counter = 0\n",
    "        output = []\n",
    "        for pair in sorted_distances_point_map.items():\n",
    "            if(counter>=k): break                           # already found K neighbours\n",
    "            # print(pair)\n",
    "            point_number, distance = pair\n",
    "            output.append(train_Y.iloc[point_number])\n",
    "            # print(train_Y.iloc[point_number])\n",
    "            counter+=1\n",
    "        \n",
    "        pred_status, trash = Counter(output).most_common()[0]\n",
    "        # print(pred_status)\n",
    "        val_pred[val_index]=pred_status\n",
    "        \n",
    "    return val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [01:58<00:00,  5.09it/s]\n"
     ]
    }
   ],
   "source": [
    "val_pred = parameter_tuning_knn(data, 3)\n",
    "val_Y\n",
    "validation_predictions = {}\n",
    "for pair in val_pred.items():\n",
    "    validation_predictions[pair[0]+2816]=pair[1]\n",
    "\n",
    "\n",
    "validation_predictions\n",
    "nocp = 0\n",
    "for point in validation_predictions:\n",
    "    if validation_predictions[point] == val_Y[point]:\n",
    "        nocp+=1\n",
    "        \n",
    "accuracy_3 = nocp/604\n",
    "list_of_accuracies = {}\n",
    "len(val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to compute accuracies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tp, tn, fp, fn \n",
    "\n",
    "if prediction is correct:\n",
    "    actual + , pred + : tp++\n",
    "    actual - , pred - : tn--\n",
    "if prediction is wrong:\n",
    "    actual + , pred - : fn++\n",
    "    actual - , pred + : fp++\n",
    "    \n",
    "\n",
    "balanced accuracy : \n",
    "    for alive class:\n",
    "        how many were classified as alive       tp\n",
    "      -------------------------------------- = -----\n",
    "          how many were actually alive         tp+fn\n",
    "    for dead class:\n",
    "        how many were classified as dead        tn\n",
    "      -------------------------------------- = -----\n",
    "          how many were actually dead          tn+fp\n",
    "\n",
    "           2tp\n",
    "f1 = ---------------\n",
    "      2tp + fp + fn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = {}\n",
    "fp = {}\n",
    "tn = {}\n",
    "fn = {}\n",
    "k = 1\n",
    "tp.setdefault(k,0)\n",
    "tn.setdefault(k,0)\n",
    "fn.setdefault(k,0)\n",
    "fp.setdefault(k,0)\n",
    "\n",
    "for point in validation_predictions:    \n",
    "    if validation_predictions[point] == val_Y[point]:\n",
    "        if val_Y[point] == 'Alive': \n",
    "            tp[k]+=1\n",
    "        else:\n",
    "            tn[k]+=1\n",
    "    else:\n",
    "        if val_Y[point] == 'Alive':\n",
    "            fn[k]+=1\n",
    "        else:\n",
    "            fp[k]+=1  \n",
    "\n",
    "tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running KNN for different K's and computing accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for k =  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [01:58<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for k =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [01:58<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for k =  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [03:57<00:00,  2.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for k =  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [01:58<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for k =  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [02:00<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for k =  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [01:58<00:00,  5.08it/s]\n"
     ]
    }
   ],
   "source": [
    "list_of_accuracies = {}\n",
    "list_of_balanced_accuracies = {}\n",
    "list_of_f1_scores = {}\n",
    "\n",
    "tp = {}\n",
    "fp = {}\n",
    "tn = {}\n",
    "fn = {}\n",
    "\n",
    "\n",
    "\n",
    "for k in tqdm([1,3,5,7,9,11], disable=True):\n",
    "    print(\"Running for k = \", k)\n",
    "    tp.setdefault(k,0)\n",
    "    tn.setdefault(k,0)\n",
    "    fn.setdefault(k,0)\n",
    "    fp.setdefault(k,0)\n",
    "    val_pred = parameter_tuning_knn(data, k)\n",
    "    \n",
    "    validation_predictions = {}\n",
    "    for pair in val_pred.items():\n",
    "        validation_predictions[pair[0]+2816]=pair[1]\n",
    "\n",
    "    nocp = 0\n",
    "    for point in validation_predictions:\n",
    "        if validation_predictions[point] == val_Y[point]:\n",
    "            nocp+=1\n",
    "\n",
    "        if validation_predictions[point] == val_Y[point]:\n",
    "            if val_Y[point] == 'Alive': \n",
    "                    tp[k]+=1\n",
    "            else:\n",
    "                tn[k]+=1\n",
    "        else:\n",
    "            if val_Y[point] == 'Alive':\n",
    "                    fn[k]+=1\n",
    "            else:\n",
    "                fp[k]+=1\n",
    "    list_of_accuracies[k] = nocp/len(val_pred)\n",
    "\n",
    "    recall_1 = tp[k]/(tp[k]+fn[k])\n",
    "    recall_2 = tn[k]/(tn[k]+fp[k])\n",
    "    list_of_balanced_accuracies[k] = 0.5*(recall_1 + recall_2)\n",
    "\n",
    "    list_of_f1_scores[k] = 2*tp[k] / (2*tp[k] + fp[k] + fn[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.8576158940397351, 3: 0.8973509933774835, 5: 0.9089403973509934, 7: 0.8940397350993378, 9: 0.9006622516556292, 11: 0.9056291390728477}\n",
      "{1: 0.7056330046469454, 3: 0.7385923155389323, 5: 0.7404170916921682, 7: 0.7071517624390797, 9: 0.7208432505950357, 11: 0.7237334240054403}\n",
      "{1: 0.9171483622350675, 3: 0.941398865784499, 5: 0.9484536082474226, 7: 0.9400749063670412, 9: 0.9438202247191011, 11: 0.9467787114845938}\n"
     ]
    }
   ],
   "source": [
    "print(list_of_accuracies)\n",
    "print(list_of_balanced_accuracies)\n",
    "print(list_of_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_set(test_X, k):\n",
    "\n",
    "    # train_X, train_Y, val_X, val_Y, test_X, test_Y = split_dataset(data=data)\n",
    "    \n",
    "    test_pred = {}\n",
    "    point_distance_map = {}\n",
    "\n",
    "    for test_index in tqdm(range(test_X.shape[0])):\n",
    "        for train_index in range(train_X.shape[0]):\n",
    "            distance = compute_distances(test_X.iloc[test_index], train_X.iloc[train_index])\n",
    "            point_distance_map[train_index] = distance\n",
    "        sorted_distances_point_map = dict(sorted(point_distance_map.items(), key=lambda item: item[1]))\n",
    "\n",
    "        counter = 0\n",
    "        output = []\n",
    "        for pair in sorted_distances_point_map.items():\n",
    "            if(counter>k): break\n",
    "            point_number, distance = pair\n",
    "            output.append(train_Y.iloc[point_number])\n",
    "\n",
    "            counter+=1\n",
    "        pred_status, trash = Counter(output).most_common()[0]\n",
    "        test_pred[test_index] = pred_status\n",
    "    \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>T Stage</th>\n",
       "      <th>N Stage</th>\n",
       "      <th>6th Stage</th>\n",
       "      <th>differentiate</th>\n",
       "      <th>Grade</th>\n",
       "      <th>A Stage</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Estrogen Status</th>\n",
       "      <th>Progesterone Status</th>\n",
       "      <th>Regional Node Examined</th>\n",
       "      <th>Regional Node Positive</th>\n",
       "      <th>Survival Months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>53</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>22</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>65</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>15</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>53</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Well differentiated</td>\n",
       "      <td>1</td>\n",
       "      <td>Regional</td>\n",
       "      <td>15</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>57</td>\n",
       "      <td>White</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>25</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>53</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>13</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>62</td>\n",
       "      <td>Other</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>9</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>56</td>\n",
       "      <td>White</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>T2</td>\n",
       "      <td>N2</td>\n",
       "      <td>IIIA</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>46</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>68</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>22</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>58</td>\n",
       "      <td>Black</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>44</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>46</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>30</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age   Race Marital Status T Stage N Stage 6th Stage  \\\n",
       "3420   53  White        Married      T2      N1       IIB   \n",
       "3421   65  White        Married      T1      N1       IIA   \n",
       "3422   53  White        Married      T1      N1       IIA   \n",
       "3423   57  White       Divorced      T2      N1       IIB   \n",
       "3424   53  White        Married      T1      N1       IIA   \n",
       "...   ...    ...            ...     ...     ...       ...   \n",
       "4019   62  Other        Married      T1      N1       IIA   \n",
       "4020   56  White       Divorced      T2      N2      IIIA   \n",
       "4021   68  White        Married      T2      N1       IIB   \n",
       "4022   58  Black       Divorced      T2      N1       IIB   \n",
       "4023   46  White        Married      T2      N1       IIB   \n",
       "\n",
       "                  differentiate Grade   A Stage  Tumor Size Estrogen Status  \\\n",
       "3420  Moderately differentiated     2  Regional          22        Positive   \n",
       "3421  Moderately differentiated     2  Regional          15        Positive   \n",
       "3422        Well differentiated     1  Regional          15        Positive   \n",
       "3423  Moderately differentiated     2  Regional          25        Positive   \n",
       "3424      Poorly differentiated     3  Regional          13        Positive   \n",
       "...                         ...   ...       ...         ...             ...   \n",
       "4019  Moderately differentiated     2  Regional           9        Positive   \n",
       "4020  Moderately differentiated     2  Regional          46        Positive   \n",
       "4021  Moderately differentiated     2  Regional          22        Positive   \n",
       "4022  Moderately differentiated     2  Regional          44        Positive   \n",
       "4023  Moderately differentiated     2  Regional          30        Positive   \n",
       "\n",
       "     Progesterone Status  Regional Node Examined  Regional Node Positive  \\\n",
       "3420            Positive                       6                       3   \n",
       "3421            Positive                       7                       2   \n",
       "3422            Positive                       2                       1   \n",
       "3423            Positive                      12                       2   \n",
       "3424            Negative                      17                       2   \n",
       "...                  ...                     ...                     ...   \n",
       "4019            Positive                       1                       1   \n",
       "4020            Positive                      14                       8   \n",
       "4021            Negative                      11                       3   \n",
       "4022            Positive                      11                       1   \n",
       "4023            Positive                       7                       2   \n",
       "\n",
       "      Survival Months  \n",
       "3420               63  \n",
       "3421               49  \n",
       "3422               69  \n",
       "3423               74  \n",
       "3424               52  \n",
       "...               ...  \n",
       "4019               49  \n",
       "4020               69  \n",
       "4021               69  \n",
       "4022               72  \n",
       "4023              100  \n",
       "\n",
       "[604 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [01:59<00:00,  5.06it/s]\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_bAcc, test_f1 = 0, 0, 0\n",
    "test_pred = run_test_set(test_X, k)\n",
    "\n",
    "test_predictions = {}\n",
    "for pair in val_pred.items():\n",
    "    test_predictions[pair[0]+3420]=pair[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3420    Alive\n",
       "3421    Alive\n",
       "3422    Alive\n",
       "3423    Alive\n",
       "3424    Alive\n",
       "        ...  \n",
       "4019    Alive\n",
       "4020    Alive\n",
       "4021    Alive\n",
       "4022    Alive\n",
       "4023    Alive\n",
       "Name: Status, Length: 604, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3420, 'Alive')\n",
      "(3421, 'Alive')\n",
      "(3422, 'Alive')\n",
      "(3423, 'Dead')\n",
      "(3424, 'Alive')\n",
      "(3425, 'Alive')\n",
      "(3426, 'Alive')\n",
      "(3427, 'Alive')\n",
      "(3428, 'Alive')\n",
      "(3429, 'Alive')\n",
      "(3430, 'Alive')\n",
      "(3431, 'Alive')\n",
      "(3432, 'Alive')\n",
      "(3433, 'Alive')\n",
      "(3434, 'Alive')\n",
      "(3435, 'Alive')\n",
      "(3436, 'Alive')\n",
      "(3437, 'Alive')\n",
      "(3438, 'Alive')\n",
      "(3439, 'Alive')\n",
      "(3440, 'Alive')\n",
      "(3441, 'Dead')\n",
      "(3442, 'Alive')\n",
      "(3443, 'Alive')\n",
      "(3444, 'Alive')\n",
      "(3445, 'Alive')\n",
      "(3446, 'Alive')\n",
      "(3447, 'Alive')\n",
      "(3448, 'Alive')\n",
      "(3449, 'Alive')\n",
      "(3450, 'Alive')\n",
      "(3451, 'Alive')\n",
      "(3452, 'Alive')\n",
      "(3453, 'Alive')\n",
      "(3454, 'Alive')\n",
      "(3455, 'Alive')\n",
      "(3456, 'Dead')\n",
      "(3457, 'Alive')\n",
      "(3458, 'Alive')\n",
      "(3459, 'Alive')\n",
      "(3460, 'Alive')\n",
      "(3461, 'Alive')\n",
      "(3462, 'Alive')\n",
      "(3463, 'Alive')\n",
      "(3464, 'Alive')\n",
      "(3465, 'Alive')\n",
      "(3466, 'Alive')\n",
      "(3467, 'Alive')\n",
      "(3468, 'Alive')\n",
      "(3469, 'Alive')\n",
      "(3470, 'Alive')\n",
      "(3471, 'Alive')\n",
      "(3472, 'Alive')\n",
      "(3473, 'Alive')\n",
      "(3474, 'Alive')\n",
      "(3475, 'Alive')\n",
      "(3476, 'Dead')\n",
      "(3477, 'Alive')\n",
      "(3478, 'Alive')\n",
      "(3479, 'Alive')\n",
      "(3480, 'Alive')\n",
      "(3481, 'Alive')\n",
      "(3482, 'Alive')\n",
      "(3483, 'Alive')\n",
      "(3484, 'Alive')\n",
      "(3485, 'Dead')\n",
      "(3486, 'Alive')\n",
      "(3487, 'Alive')\n",
      "(3488, 'Alive')\n",
      "(3489, 'Alive')\n",
      "(3490, 'Alive')\n",
      "(3491, 'Alive')\n",
      "(3492, 'Alive')\n",
      "(3493, 'Alive')\n",
      "(3494, 'Alive')\n",
      "(3495, 'Alive')\n",
      "(3496, 'Alive')\n",
      "(3497, 'Alive')\n",
      "(3498, 'Dead')\n",
      "(3499, 'Alive')\n",
      "(3500, 'Alive')\n",
      "(3501, 'Alive')\n",
      "(3502, 'Alive')\n",
      "(3503, 'Alive')\n",
      "(3504, 'Alive')\n",
      "(3505, 'Alive')\n",
      "(3506, 'Alive')\n",
      "(3507, 'Dead')\n",
      "(3508, 'Alive')\n",
      "(3509, 'Alive')\n",
      "(3510, 'Alive')\n",
      "(3511, 'Alive')\n",
      "(3512, 'Alive')\n",
      "(3513, 'Dead')\n",
      "(3514, 'Alive')\n",
      "(3515, 'Alive')\n",
      "(3516, 'Alive')\n",
      "(3517, 'Alive')\n",
      "(3518, 'Alive')\n",
      "(3519, 'Alive')\n",
      "(3520, 'Alive')\n",
      "(3521, 'Alive')\n",
      "(3522, 'Alive')\n",
      "(3523, 'Alive')\n",
      "(3524, 'Alive')\n",
      "(3525, 'Dead')\n",
      "(3526, 'Alive')\n",
      "(3527, 'Alive')\n",
      "(3528, 'Alive')\n",
      "(3529, 'Alive')\n",
      "(3530, 'Alive')\n",
      "(3531, 'Alive')\n",
      "(3532, 'Dead')\n",
      "(3533, 'Dead')\n",
      "(3534, 'Alive')\n",
      "(3535, 'Alive')\n",
      "(3536, 'Alive')\n",
      "(3537, 'Alive')\n",
      "(3538, 'Alive')\n",
      "(3539, 'Dead')\n",
      "(3540, 'Alive')\n",
      "(3541, 'Dead')\n",
      "(3542, 'Alive')\n",
      "(3543, 'Alive')\n",
      "(3544, 'Alive')\n",
      "(3545, 'Alive')\n",
      "(3546, 'Alive')\n",
      "(3547, 'Alive')\n",
      "(3548, 'Alive')\n",
      "(3549, 'Alive')\n",
      "(3550, 'Alive')\n",
      "(3551, 'Alive')\n",
      "(3552, 'Alive')\n",
      "(3553, 'Alive')\n",
      "(3554, 'Alive')\n",
      "(3555, 'Alive')\n",
      "(3556, 'Alive')\n",
      "(3557, 'Alive')\n",
      "(3558, 'Dead')\n",
      "(3559, 'Alive')\n",
      "(3560, 'Dead')\n",
      "(3561, 'Alive')\n",
      "(3562, 'Alive')\n",
      "(3563, 'Alive')\n",
      "(3564, 'Alive')\n",
      "(3565, 'Alive')\n",
      "(3566, 'Alive')\n",
      "(3567, 'Alive')\n",
      "(3568, 'Alive')\n",
      "(3569, 'Alive')\n",
      "(3570, 'Dead')\n",
      "(3571, 'Alive')\n",
      "(3572, 'Alive')\n",
      "(3573, 'Alive')\n",
      "(3574, 'Alive')\n",
      "(3575, 'Alive')\n",
      "(3576, 'Alive')\n",
      "(3577, 'Alive')\n",
      "(3578, 'Alive')\n",
      "(3579, 'Alive')\n",
      "(3580, 'Alive')\n",
      "(3581, 'Alive')\n",
      "(3582, 'Alive')\n",
      "(3583, 'Alive')\n",
      "(3584, 'Alive')\n",
      "(3585, 'Alive')\n",
      "(3586, 'Alive')\n",
      "(3587, 'Alive')\n",
      "(3588, 'Alive')\n",
      "(3589, 'Alive')\n",
      "(3590, 'Alive')\n",
      "(3591, 'Alive')\n",
      "(3592, 'Dead')\n",
      "(3593, 'Alive')\n",
      "(3594, 'Alive')\n",
      "(3595, 'Alive')\n",
      "(3596, 'Alive')\n",
      "(3597, 'Alive')\n",
      "(3598, 'Alive')\n",
      "(3599, 'Alive')\n",
      "(3600, 'Alive')\n",
      "(3601, 'Alive')\n",
      "(3602, 'Alive')\n",
      "(3603, 'Dead')\n",
      "(3604, 'Alive')\n",
      "(3605, 'Alive')\n",
      "(3606, 'Alive')\n",
      "(3607, 'Alive')\n",
      "(3608, 'Alive')\n",
      "(3609, 'Alive')\n",
      "(3610, 'Alive')\n",
      "(3611, 'Dead')\n",
      "(3612, 'Alive')\n",
      "(3613, 'Alive')\n",
      "(3614, 'Alive')\n",
      "(3615, 'Alive')\n",
      "(3616, 'Alive')\n",
      "(3617, 'Alive')\n",
      "(3618, 'Alive')\n",
      "(3619, 'Alive')\n",
      "(3620, 'Alive')\n",
      "(3621, 'Alive')\n",
      "(3622, 'Alive')\n",
      "(3623, 'Alive')\n",
      "(3624, 'Alive')\n",
      "(3625, 'Alive')\n",
      "(3626, 'Alive')\n",
      "(3627, 'Alive')\n",
      "(3628, 'Alive')\n",
      "(3629, 'Alive')\n",
      "(3630, 'Alive')\n",
      "(3631, 'Alive')\n",
      "(3632, 'Alive')\n",
      "(3633, 'Alive')\n",
      "(3634, 'Alive')\n",
      "(3635, 'Alive')\n",
      "(3636, 'Alive')\n",
      "(3637, 'Alive')\n",
      "(3638, 'Alive')\n",
      "(3639, 'Alive')\n",
      "(3640, 'Dead')\n",
      "(3641, 'Alive')\n",
      "(3642, 'Alive')\n",
      "(3643, 'Alive')\n",
      "(3644, 'Alive')\n",
      "(3645, 'Alive')\n",
      "(3646, 'Alive')\n",
      "(3647, 'Alive')\n",
      "(3648, 'Alive')\n",
      "(3649, 'Dead')\n",
      "(3650, 'Alive')\n",
      "(3651, 'Alive')\n",
      "(3652, 'Alive')\n",
      "(3653, 'Alive')\n",
      "(3654, 'Alive')\n",
      "(3655, 'Alive')\n",
      "(3656, 'Dead')\n",
      "(3657, 'Alive')\n",
      "(3658, 'Alive')\n",
      "(3659, 'Alive')\n",
      "(3660, 'Alive')\n",
      "(3661, 'Alive')\n",
      "(3662, 'Alive')\n",
      "(3663, 'Alive')\n",
      "(3664, 'Alive')\n",
      "(3665, 'Alive')\n",
      "(3666, 'Alive')\n",
      "(3667, 'Alive')\n",
      "(3668, 'Alive')\n",
      "(3669, 'Alive')\n",
      "(3670, 'Alive')\n",
      "(3671, 'Alive')\n",
      "(3672, 'Dead')\n",
      "(3673, 'Dead')\n",
      "(3674, 'Dead')\n",
      "(3675, 'Alive')\n",
      "(3676, 'Alive')\n",
      "(3677, 'Alive')\n",
      "(3678, 'Alive')\n",
      "(3679, 'Alive')\n",
      "(3680, 'Alive')\n",
      "(3681, 'Alive')\n",
      "(3682, 'Alive')\n",
      "(3683, 'Alive')\n",
      "(3684, 'Alive')\n",
      "(3685, 'Alive')\n",
      "(3686, 'Dead')\n",
      "(3687, 'Alive')\n",
      "(3688, 'Alive')\n",
      "(3689, 'Alive')\n",
      "(3690, 'Alive')\n",
      "(3691, 'Alive')\n",
      "(3692, 'Alive')\n",
      "(3693, 'Dead')\n",
      "(3694, 'Alive')\n",
      "(3695, 'Alive')\n",
      "(3696, 'Alive')\n",
      "(3697, 'Alive')\n",
      "(3698, 'Alive')\n",
      "(3699, 'Dead')\n",
      "(3700, 'Alive')\n",
      "(3701, 'Alive')\n",
      "(3702, 'Alive')\n",
      "(3703, 'Alive')\n",
      "(3704, 'Alive')\n",
      "(3705, 'Alive')\n",
      "(3706, 'Alive')\n",
      "(3707, 'Alive')\n",
      "(3708, 'Alive')\n",
      "(3709, 'Alive')\n",
      "(3710, 'Dead')\n",
      "(3711, 'Alive')\n",
      "(3712, 'Dead')\n",
      "(3713, 'Alive')\n",
      "(3714, 'Alive')\n",
      "(3715, 'Alive')\n",
      "(3716, 'Alive')\n",
      "(3717, 'Alive')\n",
      "(3718, 'Alive')\n",
      "(3719, 'Alive')\n",
      "(3720, 'Alive')\n",
      "(3721, 'Alive')\n",
      "(3722, 'Alive')\n",
      "(3723, 'Alive')\n",
      "(3724, 'Alive')\n",
      "(3725, 'Alive')\n",
      "(3726, 'Alive')\n",
      "(3727, 'Alive')\n",
      "(3728, 'Alive')\n",
      "(3729, 'Alive')\n",
      "(3730, 'Alive')\n",
      "(3731, 'Alive')\n",
      "(3732, 'Dead')\n",
      "(3733, 'Alive')\n",
      "(3734, 'Alive')\n",
      "(3735, 'Alive')\n",
      "(3736, 'Dead')\n",
      "(3737, 'Alive')\n",
      "(3738, 'Alive')\n",
      "(3739, 'Dead')\n",
      "(3740, 'Alive')\n",
      "(3741, 'Alive')\n",
      "(3742, 'Dead')\n",
      "(3743, 'Alive')\n",
      "(3744, 'Alive')\n",
      "(3745, 'Alive')\n",
      "(3746, 'Alive')\n",
      "(3747, 'Alive')\n",
      "(3748, 'Alive')\n",
      "(3749, 'Alive')\n",
      "(3750, 'Alive')\n",
      "(3751, 'Alive')\n",
      "(3752, 'Alive')\n",
      "(3753, 'Alive')\n",
      "(3754, 'Alive')\n",
      "(3755, 'Alive')\n",
      "(3756, 'Alive')\n",
      "(3757, 'Alive')\n",
      "(3758, 'Alive')\n",
      "(3759, 'Alive')\n",
      "(3760, 'Alive')\n",
      "(3761, 'Alive')\n",
      "(3762, 'Alive')\n",
      "(3763, 'Alive')\n",
      "(3764, 'Alive')\n",
      "(3765, 'Alive')\n",
      "(3766, 'Alive')\n",
      "(3767, 'Alive')\n",
      "(3768, 'Alive')\n",
      "(3769, 'Alive')\n",
      "(3770, 'Alive')\n",
      "(3771, 'Alive')\n",
      "(3772, 'Alive')\n",
      "(3773, 'Alive')\n",
      "(3774, 'Alive')\n",
      "(3775, 'Alive')\n",
      "(3776, 'Alive')\n",
      "(3777, 'Alive')\n",
      "(3778, 'Alive')\n",
      "(3779, 'Alive')\n",
      "(3780, 'Alive')\n",
      "(3781, 'Alive')\n",
      "(3782, 'Alive')\n",
      "(3783, 'Dead')\n",
      "(3784, 'Alive')\n",
      "(3785, 'Dead')\n",
      "(3786, 'Alive')\n",
      "(3787, 'Alive')\n",
      "(3788, 'Alive')\n",
      "(3789, 'Alive')\n",
      "(3790, 'Alive')\n",
      "(3791, 'Alive')\n",
      "(3792, 'Alive')\n",
      "(3793, 'Alive')\n",
      "(3794, 'Alive')\n",
      "(3795, 'Alive')\n",
      "(3796, 'Alive')\n",
      "(3797, 'Alive')\n",
      "(3798, 'Alive')\n",
      "(3799, 'Alive')\n",
      "(3800, 'Alive')\n",
      "(3801, 'Alive')\n",
      "(3802, 'Alive')\n",
      "(3803, 'Alive')\n",
      "(3804, 'Alive')\n",
      "(3805, 'Alive')\n",
      "(3806, 'Alive')\n",
      "(3807, 'Alive')\n",
      "(3808, 'Alive')\n",
      "(3809, 'Alive')\n",
      "(3810, 'Dead')\n",
      "(3811, 'Alive')\n",
      "(3812, 'Alive')\n",
      "(3813, 'Alive')\n",
      "(3814, 'Alive')\n",
      "(3815, 'Alive')\n",
      "(3816, 'Alive')\n",
      "(3817, 'Alive')\n",
      "(3818, 'Alive')\n",
      "(3819, 'Alive')\n",
      "(3820, 'Alive')\n",
      "(3821, 'Alive')\n",
      "(3822, 'Alive')\n",
      "(3823, 'Alive')\n",
      "(3824, 'Alive')\n",
      "(3825, 'Dead')\n",
      "(3826, 'Alive')\n",
      "(3827, 'Alive')\n",
      "(3828, 'Alive')\n",
      "(3829, 'Dead')\n",
      "(3830, 'Alive')\n",
      "(3831, 'Alive')\n",
      "(3832, 'Alive')\n",
      "(3833, 'Alive')\n",
      "(3834, 'Alive')\n",
      "(3835, 'Alive')\n",
      "(3836, 'Alive')\n",
      "(3837, 'Alive')\n",
      "(3838, 'Alive')\n",
      "(3839, 'Alive')\n",
      "(3840, 'Alive')\n",
      "(3841, 'Alive')\n",
      "(3842, 'Alive')\n",
      "(3843, 'Alive')\n",
      "(3844, 'Alive')\n",
      "(3845, 'Alive')\n",
      "(3846, 'Alive')\n",
      "(3847, 'Alive')\n",
      "(3848, 'Dead')\n",
      "(3849, 'Dead')\n",
      "(3850, 'Alive')\n",
      "(3851, 'Alive')\n",
      "(3852, 'Alive')\n",
      "(3853, 'Alive')\n",
      "(3854, 'Alive')\n",
      "(3855, 'Alive')\n",
      "(3856, 'Alive')\n",
      "(3857, 'Dead')\n",
      "(3858, 'Alive')\n",
      "(3859, 'Alive')\n",
      "(3860, 'Alive')\n",
      "(3861, 'Alive')\n",
      "(3862, 'Alive')\n",
      "(3863, 'Alive')\n",
      "(3864, 'Alive')\n",
      "(3865, 'Alive')\n",
      "(3866, 'Alive')\n",
      "(3867, 'Alive')\n",
      "(3868, 'Alive')\n",
      "(3869, 'Alive')\n",
      "(3870, 'Alive')\n",
      "(3871, 'Dead')\n",
      "(3872, 'Alive')\n",
      "(3873, 'Alive')\n",
      "(3874, 'Alive')\n",
      "(3875, 'Alive')\n",
      "(3876, 'Alive')\n",
      "(3877, 'Alive')\n",
      "(3878, 'Alive')\n",
      "(3879, 'Alive')\n",
      "(3880, 'Alive')\n",
      "(3881, 'Alive')\n",
      "(3882, 'Alive')\n",
      "(3883, 'Alive')\n",
      "(3884, 'Alive')\n",
      "(3885, 'Alive')\n",
      "(3886, 'Alive')\n",
      "(3887, 'Alive')\n",
      "(3888, 'Alive')\n",
      "(3889, 'Alive')\n",
      "(3890, 'Dead')\n",
      "(3891, 'Alive')\n",
      "(3892, 'Alive')\n",
      "(3893, 'Alive')\n",
      "(3894, 'Alive')\n",
      "(3895, 'Alive')\n",
      "(3896, 'Alive')\n",
      "(3897, 'Alive')\n",
      "(3898, 'Alive')\n",
      "(3899, 'Alive')\n",
      "(3900, 'Alive')\n",
      "(3901, 'Alive')\n",
      "(3902, 'Alive')\n",
      "(3903, 'Alive')\n",
      "(3904, 'Alive')\n",
      "(3905, 'Alive')\n",
      "(3906, 'Alive')\n",
      "(3907, 'Dead')\n",
      "(3908, 'Alive')\n",
      "(3909, 'Alive')\n",
      "(3910, 'Alive')\n",
      "(3911, 'Alive')\n",
      "(3912, 'Alive')\n",
      "(3913, 'Alive')\n",
      "(3914, 'Alive')\n",
      "(3915, 'Alive')\n",
      "(3916, 'Alive')\n",
      "(3917, 'Alive')\n",
      "(3918, 'Alive')\n",
      "(3919, 'Dead')\n",
      "(3920, 'Alive')\n",
      "(3921, 'Alive')\n",
      "(3922, 'Alive')\n",
      "(3923, 'Alive')\n",
      "(3924, 'Alive')\n",
      "(3925, 'Alive')\n",
      "(3926, 'Alive')\n",
      "(3927, 'Alive')\n",
      "(3928, 'Alive')\n",
      "(3929, 'Alive')\n",
      "(3930, 'Alive')\n",
      "(3931, 'Alive')\n",
      "(3932, 'Alive')\n",
      "(3933, 'Alive')\n",
      "(3934, 'Alive')\n",
      "(3935, 'Alive')\n",
      "(3936, 'Alive')\n",
      "(3937, 'Dead')\n",
      "(3938, 'Alive')\n",
      "(3939, 'Alive')\n",
      "(3940, 'Alive')\n",
      "(3941, 'Alive')\n",
      "(3942, 'Alive')\n",
      "(3943, 'Alive')\n",
      "(3944, 'Alive')\n",
      "(3945, 'Alive')\n",
      "(3946, 'Alive')\n",
      "(3947, 'Alive')\n",
      "(3948, 'Alive')\n",
      "(3949, 'Alive')\n",
      "(3950, 'Alive')\n",
      "(3951, 'Alive')\n",
      "(3952, 'Alive')\n",
      "(3953, 'Alive')\n",
      "(3954, 'Alive')\n",
      "(3955, 'Alive')\n",
      "(3956, 'Alive')\n",
      "(3957, 'Alive')\n",
      "(3958, 'Alive')\n",
      "(3959, 'Alive')\n",
      "(3960, 'Alive')\n",
      "(3961, 'Alive')\n",
      "(3962, 'Alive')\n",
      "(3963, 'Alive')\n",
      "(3964, 'Alive')\n",
      "(3965, 'Alive')\n",
      "(3966, 'Alive')\n",
      "(3967, 'Alive')\n",
      "(3968, 'Alive')\n",
      "(3969, 'Alive')\n",
      "(3970, 'Dead')\n",
      "(3971, 'Alive')\n",
      "(3972, 'Alive')\n",
      "(3973, 'Alive')\n",
      "(3974, 'Alive')\n",
      "(3975, 'Alive')\n",
      "(3976, 'Alive')\n",
      "(3977, 'Alive')\n",
      "(3978, 'Alive')\n",
      "(3979, 'Alive')\n",
      "(3980, 'Alive')\n",
      "(3981, 'Alive')\n",
      "(3982, 'Alive')\n",
      "(3983, 'Alive')\n",
      "(3984, 'Alive')\n",
      "(3985, 'Alive')\n",
      "(3986, 'Alive')\n",
      "(3987, 'Alive')\n",
      "(3988, 'Alive')\n",
      "(3989, 'Alive')\n",
      "(3990, 'Alive')\n",
      "(3991, 'Alive')\n",
      "(3992, 'Alive')\n",
      "(3993, 'Alive')\n",
      "(3994, 'Alive')\n",
      "(3995, 'Alive')\n",
      "(3996, 'Alive')\n",
      "(3997, 'Dead')\n",
      "(3998, 'Dead')\n",
      "(3999, 'Alive')\n",
      "(4000, 'Alive')\n",
      "(4001, 'Alive')\n",
      "(4002, 'Alive')\n",
      "(4003, 'Alive')\n",
      "(4004, 'Alive')\n",
      "(4005, 'Dead')\n",
      "(4006, 'Alive')\n",
      "(4007, 'Alive')\n",
      "(4008, 'Alive')\n",
      "(4009, 'Alive')\n",
      "(4010, 'Alive')\n",
      "(4011, 'Alive')\n",
      "(4012, 'Alive')\n",
      "(4013, 'Alive')\n",
      "(4014, 'Alive')\n",
      "(4015, 'Dead')\n",
      "(4016, 'Alive')\n",
      "(4017, 'Alive')\n",
      "(4018, 'Alive')\n",
      "(4019, 'Alive')\n",
      "(4020, 'Alive')\n",
      "(4021, 'Alive')\n",
      "(4022, 'Alive')\n",
      "(4023, 'Alive')\n"
     ]
    }
   ],
   "source": [
    "for point in test_predictions:\n",
    "    if test_predictions[point] == test_Y[point]:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.8576158940397351,\n",
       " 3: 0.8973509933774835,\n",
       " 5: 0.9089403973509934,\n",
       " 7: 0.8940397350993378,\n",
       " 9: 0.9006622516556292,\n",
       " 11: 0.9056291390728477}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_accuracies\n",
    "tp, fp, tn, fn\n",
    "list_of_balanced_accuracies = {}\n",
    "\n",
    "\n",
    "for k in [1,3,5,7,9,11]:\n",
    "    recall_1 = tp[k]/(tp[k]+fn[k])\n",
    "    recall_2 = tn[k]/(tn[k]+fp[k])\n",
    "    list_of_balanced_accuracies[k] = 0.5*(recall_1 + recall_2)\n",
    "list_of_balanced_accuracies\n",
    "\"\"\"\n",
    "\n",
    "           2tp\n",
    "f1 = ---------------\n",
    "      2tp + fp + fn \n",
    "\n",
    "\"\"\"\n",
    "list_of_f1_scores = {}\n",
    "for k in [1,3,5,9,11]:\n",
    "    list_of_f1_scores[k] = 2*tp[k] / (2*tp[k] + fp[k] + fn[k])\n",
    "list_of_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Acc, BAcc and F1 scores, the optimal K- values are:\n",
    "    1. Based on Acc         : 5\n",
    "    2. Based on Bacc        : 5\n",
    "    3. Based on F1 scores   : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_test = {}\n",
    "tn_test = {}\n",
    "fp_test = {}\n",
    "fn_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.setdefault(k,0)\n",
    "tn.setdefault(k,0)\n",
    "fn.setdefault(k,0)\n",
    "fp.setdefault(k,0)\n",
    "test_pred = parameter_tuning_knn(data, k)\n",
    "\n",
    "test_predictions = {}\n",
    "for pair in test_pred.items():\n",
    "    test_predictions[pair[0]+2816]=pair[1]\n",
    "\n",
    "nocp = 0\n",
    "for point in test_predictions:\n",
    "    if test_predictions[point] == val_Y[point]:\n",
    "        nocp+=1\n",
    "\n",
    "    if test_predictions[point] == val_Y[point]:\n",
    "        if val_Y[point] == 'Alive': \n",
    "                tp[k]+=1\n",
    "        else:\n",
    "            tn[k]+=1\n",
    "    else:\n",
    "        if val_Y[point] == 'Alive':\n",
    "                fn[k]+=1\n",
    "        else:\n",
    "            fp[k]+=1\n",
    "list_of_accuracies[k] = nocp/len(test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
